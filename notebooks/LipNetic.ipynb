{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_PATH = \"/media/artem/data/Dataset/faces/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [05:24<00:00,  9.82s/it]\n"
     ]
    }
   ],
   "source": [
    "def fixname(s):\n",
    "    return s.split('_')[2]\n",
    "\n",
    "speakers = {}\n",
    "for s in tqdm(os.listdir(FRAME_PATH)):\n",
    "    PATH = path.join(FRAME_PATH, s)\n",
    "    speakers[s] = {}\n",
    "    for folder in os.listdir(PATH):\n",
    "        PATH2 = path.join(PATH, folder)\n",
    "        speakers[s][fixname(folder)] = []\n",
    "        for filename in sorted(os.listdir(PATH2), key=lambda x: int(x.split('_')[1].split('.')[0])):\n",
    "            speakers[s][fixname(folder)].append(imread(path.join(PATH2, filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:01<00:00, 21.24it/s]\n"
     ]
    }
   ],
   "source": [
    "WORD_PATH = \"/media/artem/data/WLAS/scripts/gridcorpus/words/\"\n",
    "\n",
    "def fixname(s):\n",
    "    return s.split('.')[0]\n",
    "\n",
    "word_alignments = {}\n",
    "for s in tqdm(os.listdir(WORD_PATH)):\n",
    "    PATH = path.join(WORD_PATH, s, \"align\")\n",
    "    word_alignments[s] = {}\n",
    "    for filename in os.listdir(PATH):\n",
    "        word_alignments[s][fixname(filename)] = []\n",
    "        with open(path.join(PATH, filename)) as ftr:\n",
    "            for line in ftr:\n",
    "                l1, l2, w = line.split()\n",
    "                l1 = round(int(l1) / 1000) - 1\n",
    "                l2 = round(int(l2) / 1000) + 1\n",
    "                word_alignments[s][fixname(filename)].append((w, l1, l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sil', -1, 12),\n",
       " ('set', 10, 21),\n",
       " ('blue', 19, 26),\n",
       " ('by', 24, 29),\n",
       " ('u', 27, 33),\n",
       " ('one', 31, 39),\n",
       " ('soon', 37, 49),\n",
       " ('sil', 47, 75)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_alignments['s1']['sbbu1s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "MAX_WORDS = 8\n",
    "MAX_FRAMES = 8\n",
    "for_valida = [\"s5\", \"s14\"]\n",
    "\n",
    "def encode_words(s):\n",
    "    res = []\n",
    "    for word, _, _ in s:\n",
    "        if word == 'sil':\n",
    "            res.append(27)\n",
    "        else:\n",
    "            #print(word, s)\n",
    "            res.extend(ord(a) - ord('a') + 1 for a in word)\n",
    "            res.append(27)\n",
    "    if s[-1][0] != 'sil':\n",
    "        res.pop()\n",
    "    return res\n",
    "\n",
    "def generate_XY(speakers, word_alignments, words_lengths=(1, 2), frame_length=24, drop_rate=0.8):\n",
    "    X, Y = [], []\n",
    "    for s in speakers.keys():\n",
    "        if s in for_valida:\n",
    "            continue\n",
    "        for vid in speakers[s].keys():\n",
    "            if len(speakers[s][vid]) == 75 and vid in word_alignments[s] and np.random.rand() > drop_rate:\n",
    "                length = np.random.choice(np.arange(*words_lengths)) \n",
    "                pos = np.random.choice(len(word_alignments[s][vid]) - length + 1)\n",
    "                if word_alignments[s][vid][pos][0] == 'sil':\n",
    "                    continue\n",
    "                l, r = word_alignments[s][vid][pos][1], word_alignments[s][vid][pos + length - 1][2]\n",
    "                l = max(0, l)\n",
    "                if (r - l > frame_length):\n",
    "                    continue\n",
    "                X.append(speakers[s][vid][l:r])\n",
    "                Y.append(encode_words(word_alignments[s][vid][pos:pos+length]))\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = generate_XY(speakers, word_alignments, drop_rate=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_zeros(X):\n",
    "    max_len = max(len(x) for x in X)\n",
    "    return np.array([x + [np.zeros((120, 120)) for i in range(max_len - len(x))] for x in X])\n",
    "\n",
    "def iterate_batch(X, Y, batch_size=32):\n",
    "    ind = np.arange(len(X))\n",
    "    np.random.shuffle(ind)\n",
    "    X = [X[i] for i in ind]\n",
    "    Y = [Y[i] for i in ind]\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        yield X[i:i+batch_size], Y[i:i+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        out_x = x.transpose(1, 2)\n",
    "        out_x = out_x.contiguous()\n",
    "        dims = out_x.size()\n",
    "        out_x = out_x.view(dims[0], dims[1], dims[2]*dims[3]*dims[4])\n",
    "        return out_x\n",
    "\n",
    "class LipNet(nn.Module):\n",
    "    def __init__(self, hidden_size=256, vocab_size=28, n_layers=1, in_channels=1):\n",
    "        super(LipNet, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.in_channels = in_channels\n",
    "        self.conv1 = nn.Conv3d(in_channels=self.in_channels, out_channels=32, kernel_size=(3, 7, 7), \n",
    "                               stride=(1, 2, 2), padding=(1, 1, 1))\n",
    "        self.pooling = nn.MaxPool3d((1, 2, 2))\n",
    "        #self.batchnorm1 = nn.BatchNorm3d(32)\n",
    "        self.conv2 = nn.Conv3d(in_channels=32, out_channels=64, kernel_size=(3, 5, 5), \n",
    "                               stride=(1, 1, 1), padding=(1, 1, 1))\n",
    "        #self.batchnorm2 = nn.BatchNorm3d(64)\n",
    "        self.conv3 = nn.Conv3d(in_channels=64, out_channels=96, kernel_size=(3, 5, 5), \n",
    "                               stride=(1, 1, 1), padding=(1, 1, 1))\n",
    "        #self.batchnorm3 = nn.BatchNorm3d(96)\n",
    "        self.flat = Flatten()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.gru1 = nn.GRU(input_size=2400, hidden_size=hidden_size, num_layers=self.n_layers, \n",
    "                           bidirectional=True, batch_first=True)\n",
    "        self.gru2 = nn.GRU(input_size=512, hidden_size=hidden_size, num_layers=self.n_layers, \n",
    "                           bidirectional=True, batch_first=True)\n",
    "        self.dense1 = nn.Linear(512, 28)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = self.relu(self.conv1(input))\n",
    "        output = self.pooling(output)\n",
    "        output = self.relu(self.conv2(output))\n",
    "        output = self.pooling(output)\n",
    "        output = self.relu(self.conv3(output))\n",
    "\n",
    "        output = self.pooling(output)\n",
    "        output = self.flat(output)\n",
    "        #print(output.shape)\n",
    "        #print(output.size())\n",
    "        output, hidden = self.gru1(output)\n",
    "        output, hidden = self.gru2(output)\n",
    "        output = self.dense1(output)\n",
    "        #print(output.size())\n",
    "        output = self.softmax(output)\n",
    "        return output\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return Variable(torch.zeros(2, batch_size, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "1.00000e-02 *\n",
       "  3.4881  3.4876  3.6033  ...   3.4399  3.3461  3.6148\n",
       "  3.4942  3.4727  3.6140  ...   3.4282  3.3394  3.6176\n",
       "  3.4938  3.4736  3.6194  ...   3.4211  3.3364  3.6144\n",
       "           ...             ⋱             ...          \n",
       "  3.4924  3.5291  3.6018  ...   3.4158  3.3484  3.6287\n",
       "  3.4991  3.5388  3.5817  ...   3.4264  3.3660  3.6382\n",
       "  3.5128  3.5501  3.5549  ...   3.4509  3.3895  3.6470\n",
       "[torch.FloatTensor of size 1x75x28]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln = LipNet()\n",
    "hidden = ln.init_hidden(1)\n",
    "a = torch.Tensor(1, 1, 75, 120, 120).zero_()\n",
    "test_fuck = Variable(a)\n",
    "ln(test_fuck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LipNet().cuda()\n",
    "optimizer = Adam(model.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warpctc_pytorch import CTCLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  8.61it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1518244421288/work/torch/lib/THC/generic/THCStorage.cu:58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-616c40598253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#print(x_lengths.size(0), x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#hidden = model.init_hidden(x.size(0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_lengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-15ca158c166c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1518244421288/work/torch/lib/THC/generic/THCStorage.cu:58"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "n_epoch = 100\n",
    "criterion = CTCLoss()\n",
    "mean_loss = 0\n",
    "loss_log = []\n",
    "for epoch in range(n_epoch):\n",
    "    print(epoch)\n",
    "    X, Y = generate_XY(speakers, word_alignments, frame_length=30, drop_rate=0.5)\n",
    "    for i, (x, y) in enumerate(tqdm(iterate_batch(X, Y))):\n",
    "        x_lengths = Variable(torch.IntTensor([len(rx) for rx in x]))\n",
    "        x = Variable(torch.FloatTensor(add_zeros([[tx / 256 - 0.5 for tx in rx] for rx in x]))).cuda()\n",
    "        x = x.view(x.shape[0], 1, *x.shape[1:])\n",
    "        y_lengths = Variable(torch.IntTensor([len(ry) for ry in y]))\n",
    "        #print([z for by in y for z in by])\n",
    "        y = Variable(torch.IntTensor([z for by in y for z in by]))\n",
    "        #print(x_lengths.size(0), x.shape)\n",
    "        #hidden = model.init_hidden(x.size(0))\n",
    "        out = model(x).transpose(0, 1)\n",
    "        loss = criterion(out, y, x_lengths, y_lengths) / x.size(0)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_log.append(loss.data[0])\n",
    "        if i % 50 == 49:\n",
    "            clear_output()\n",
    "            plt.plot(loss_log)\n",
    "            plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
